{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Network Graph Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore interactive design and parameters combo to better detect adn define interactions between members. \n",
    "\n",
    "Code credits - Yumeng Xi\n",
    "CHanged based on the original code provided by Xavier Lambein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import logging\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Import the data analysis tools\n",
    "import openbadge_analysis as ob\n",
    "import openbadge_analysis.preprocessing\n",
    "import openbadge_analysis.core\n",
    "# import pyvis\n",
    "\n",
    "SELECTED_BEACON = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings\n",
    "The time_zone variable will be used when converting the timestamp form UTC time to your local time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zone = 'US/Eastern'\n",
    "log_version = '2.0'\n",
    "time_bins_size = '1min'\n",
    "\n",
    "proximity_data_filenames = []\n",
    "\n",
    "for i in range(1, 18):\n",
    "    if i < 10:\n",
    "        filename = 'CTSIserver{:02d}_proximity_2019-06-01.txt'.format(i)\n",
    "    else:\n",
    "        filename = 'CTSIserver{}_proximity_2019-06-01.txt'.format(i)\n",
    "        \n",
    "    proximity_data_filenames.append(filename)\n",
    "    \n",
    "attendees_metadata_filename = \"Badge assignments_Attendees_2019.xlsx\"\n",
    "members_metadata_filename = \"Member-2019-05-28.csv\"\n",
    "beacons_metadata_filename = \"location table.xlsx\"\n",
    "data_dir = \"./proximity_2019-06-01/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load two lists that will help us with some of the analysis: list of membmers and list of location beacons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_metadata = pd.read_csv(data_dir+members_metadata_filename)\n",
    "beacons_metadata = pd.read_excel(data_dir+beacons_metadata_filename, sheet_name='Sheet1')\n",
    "\n",
    "# Calculating the id of the beacon based on it's MAC address\n",
    "# beacons_metadata['id'] = beacons_metadata.apply(\n",
    "#     lambda row: ob.core.mac_address_to_id(row['badge_address']),\n",
    "#     axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read member background data, merge to the original member metadata to keep consistent\n",
    "background = pd.read_excel(data_dir+'Badge assignments_Attendees_2019.xlsx')\n",
    "cleaned_members = members_metadata.merge(background, how='inner')\n",
    "\n",
    "# separate out the member key strings of people who actually attended the meeting and those who did not\n",
    "attendees_key = set(cleaned_members['member'])\n",
    "all_people_key = set(members_metadata['member'])\n",
    "attendees_id = set(cleaned_members['id'])\n",
    "all_people_id = set(members_metadata['id'])\n",
    "\n",
    "non_attendees_key = all_people_key-attendees_key\n",
    "non_attendees_id = all_people_id-attendees_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beacons_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a translation table between the badge ID and member key. This is done based on the data itself, since it should contain data from all the badges that take part in the study. \n",
    "\n",
    "Note that we create a <id,member key> pair for ever time bin. While this is not necessary at this point, it allows this mapping to change (for example, if a badge is re-assigned to a different member)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idmaps = []\n",
    "\n",
    "for proximity_data_filename in proximity_data_filenames:\n",
    "    with open(os.path.join(data_dir, proximity_data_filename), 'r') as f:\n",
    "        idmaps.append(ob.preprocessing.id_to_member_mapping(f, time_bins_size, tz=time_zone))\n",
    "        \n",
    "tmp_idmaps = idmaps[0]\n",
    "for i in range(1, len(idmaps)):\n",
    "    tmp_idmaps = pd.concat([tmp_idmaps, idmaps[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_idmaps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this translation table and the proximity data, we can create a list of \"pings\" - every time two badges were in close proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2badges = []\n",
    "\n",
    "for proximity_data_filename in proximity_data_filenames:\n",
    "    with open(os.path.join(data_dir, proximity_data_filename), 'r') as f:\n",
    "        m2badges.append(ob.preprocessing.member_to_badge_proximity(f, time_bins_size, tz=time_zone))\n",
    "        \n",
    "tmp_m2badges = m2badges[0]\n",
    "\n",
    "for i in range(1, len(m2badges)):\n",
    "    tmp_m2badges = pd.concat([tmp_m2badges, m2badges[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_m2badges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_m2badges = []\n",
    "\n",
    "for m2badge in m2badges:\n",
    "    drop_list = []\n",
    "    tmp = m2badge.reset_index()\n",
    "\n",
    "    for index, row in tmp.iterrows():\n",
    "        if row['member'] in non_attendees_key:\n",
    "            drop_list.append(index)\n",
    "        else:\n",
    "            if row['observed_id'] in non_attendees_id:\n",
    "                drop_list.append(index)\n",
    "    tmp = tmp.drop(drop_list)\n",
    "    cleaned_m2badges.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a badge can either be a badge worn by a participant, or a location beacon, we split the dataset into member-to-member (for network graphs) and member-to-beacon (for localization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Member to member\n",
    "m2ms = []\n",
    "for (m2badge, idmap) in zip(cleaned_m2badges, idmaps):\n",
    "    m2ms.append(ob.preprocessing.member_to_member_proximity(m2badge, idmap))\n",
    "\n",
    "tmp_m2ms = m2ms[0]\n",
    "for i in range(1, len(m2ms)):\n",
    "    tmp_m2ms = pd.concat([tmp_m2ms, m2ms[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_m2ms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Member to location beacon\n",
    "m2bs = []\n",
    "for m2badge in cleaned_m2badges:\n",
    "    m2bs.append(ob.preprocessing.member_to_beacon_proximity(m2badge, beacons_metadata.set_index('id')['beacon']))\n",
    "    \n",
    "tmp_m2bs = m2bs[0]\n",
    "for i in range(1, len(m2bs)):\n",
    "    tmp_m2bs = pd.concat([tmp_m2bs, m2bs[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Graph Preparation \n",
    "Run every block in under this title to prepare for all Dynamic Network Member Graph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time slices\n",
    "def generate_time_slices(start_h, start_m, end_h, end_m, interval=2):\n",
    "    time_slices = []\n",
    "    tmp_time = '2019-06-01 {:02}:{:02}'.format(start_h, start_m)\n",
    "    duration = (end_h - start_h) * 60 + (end_m - start_m)\n",
    "    for i in range(duration/interval+1):\n",
    "        if start_m < 60-interval+1:\n",
    "            start_m += interval-1\n",
    "        else:\n",
    "            start_h += 1\n",
    "            start_m = start_m - 60 + interval\n",
    "                \n",
    "        if start_h>=end_h and start_m>=end_m:\n",
    "            time_slices.append(slice(tmp_time,'2019-06-01 {:02}:{:02}'.format(end_h, end_m)))\n",
    "            break\n",
    "        \n",
    "        tmp_time = '2019-06-01 {:02}:{:02}'.format(start_h, start_m)\n",
    "        time_slices.append(slice(start, tmp_time))\n",
    "        \n",
    "        if start_m >= 59:\n",
    "            start = '2019-06-01 {:02}:{:02}'.format(start_h+1, 0)\n",
    "        else:\n",
    "            start_m += 1\n",
    "            start = '2019-06-01 {:02}:{:02}'.format(start_h, start_m)\n",
    "        \n",
    "    return time_slices\n",
    "# generate_time_slices(9,50,11,30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time slices\n",
    "def generate_time_slices(start_h, start_m, end_h, end_m, interval=2):\n",
    "    \n",
    "    time_slices = []\n",
    "    \n",
    "    start = '2019-06-01 {:02}:{:02}'.format(start_h, start_m)\n",
    "    duration = (end_h - start_h) * 60 + (end_m - start_m)\n",
    "    \n",
    "    for i in range(duration/interval+1):\n",
    "        \n",
    "        if start_h > end_h:\n",
    "            break\n",
    "        elif start_h == end_h:\n",
    "            if start_m > end_m:\n",
    "                break\n",
    "            \n",
    "        tmp_h = start_h\n",
    "        tmp_m = start_m\n",
    "        \n",
    "        if tmp_m < 60-interval+1:\n",
    "            tmp_m += interval-1\n",
    "        else:\n",
    "            tmp_h += 1\n",
    "            if interval > 1:\n",
    "                tmp_m = tmp_m - 60 + interval-1\n",
    "            else:\n",
    "                tmp_m = tmp_m - 60 + interval\n",
    "            \n",
    "        tmp_time = '2019-06-01 {:02}:{:02}'.format(tmp_h, tmp_m)\n",
    "        \n",
    "        time_slices.append(slice(start, tmp_time))\n",
    "        \n",
    "        start_h = tmp_h\n",
    "        start_m = tmp_m\n",
    "        \n",
    "        if start_m == 59:\n",
    "            start_h += 1\n",
    "            start_m = 0\n",
    "        else:\n",
    "            start_m += 1\n",
    "        \n",
    "        start = '2019-06-01 {:02}:{:02}'.format(start_h, start_m)\n",
    "    return time_slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time slices\n",
    "def generate_time_points(start_h, start_m, end_h, end_m, interval=2):\n",
    "    time_points = []\n",
    "    tmp_time = '2019-06-01 {:02}:{:02}'.format(start_h, start_m)\n",
    "    duration = (end_h - start_h) * 60 + (end_m - start_m)\n",
    "    start_m=start_m-1\n",
    "    for i in range(duration/interval+1):\n",
    "        if start_m < 60-interval:\n",
    "            start_m += interval\n",
    "        else:\n",
    "            start_h += 1\n",
    "            start_m = start_m - 60 + interval\n",
    "        tmp_time = '2019-06-01 {:02}:{:02}'.format(start_h, start_m)\n",
    "        if start_h>=end_h and start_m>=end_m:\n",
    "            tmp_time = '2019-06-01 {:02}:{:02}'.format(end_h, end_m)\n",
    "            time_points.append(tmp_time)\n",
    "            break\n",
    "        time_points.append(tmp_time)\n",
    "        \n",
    "    return time_points\n",
    "\n",
    "# generate_time_points(9,50,11,30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_m2ms_sorted = tmp_m2ms.sort_index(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_graph(G, graph_layout='shell',\n",
    "               node_size=200, node_color='blue', node_alpha=0.3,\n",
    "               node_text_size=8,\n",
    "               edge_color='blue', edge_alpha=0.3, edge_tickness=1,\n",
    "               edge_text_pos=0.3,\n",
    "               text_font='sans-serif'):\n",
    "\n",
    "    # these are different layouts for the network you may try\n",
    "    # shell seems to work best\n",
    "    if graph_layout == 'spring':\n",
    "        graph_pos=nx.spring_layout(G)\n",
    "    elif graph_layout == 'spectral':\n",
    "        graph_pos=nx.spectral_layout(G)\n",
    "    elif graph_layout == 'random':\n",
    "        graph_pos=nx.random_layout(G)\n",
    "    else:\n",
    "        graph_pos=nx.shell_layout(G)\n",
    "\n",
    "    # draw graph\n",
    "    nx.draw_networkx_nodes(G,graph_pos,node_size=node_size, \n",
    "                           alpha=node_alpha, node_color=node_color, cmap=plt.get_cmap('jet'))\n",
    "    nx.draw_networkx_edges(G,graph_pos,width=edge_tickness,\n",
    "                           alpha=edge_alpha,edge_color=edge_color)\n",
    "    nx.draw_networkx_labels(G, graph_pos,font_size=node_text_size,\n",
    "                            font_family=text_font)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Graph Basic Example\n",
    "This trunk is only for demonstration, not for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data from specific time period\n",
    "\n",
    "time_slice = slice('2019-06-01 10:00', '2019-06-01 11:20')\n",
    "m2m_breakout = tmp_m2ms_sorted.loc[time_slice]\n",
    "\n",
    "# keep only instances with strong signal\n",
    "m2m_filter_rssi = m2m_breakout[m2m_breakout.rssi >= -70].copy()\n",
    "print(len(m2m_filter_rssi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of time members were in close proximity\n",
    "# We name the count column \"weight\" so that networkx will use it as weight for the spring layout\n",
    "m2m_edges = m2m_filter_rssi.groupby(['member1', 'member2'])[['rssi_weighted_mean']].count().rename(columns={'rssi_weighted_mean':'weight'})\n",
    "m2m_edges = m2m_edges[[\"weight\"]].reset_index()\n",
    "\n",
    "# Keep strongest edges (threshold set manually)\n",
    "m2m_edges = m2m_edges[m2m_edges.weight > 15]\n",
    "print(len(m2m_edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph\n",
    "graph=nx.from_pandas_edgelist(m2m_edges, \"member1\", \"member2\", \"weight\")\n",
    "fig = plt.figure(figsize=(12, 10), dpi=150)\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "draw_graph(graph, graph_layout=\"spring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create an dragable interface of nodes\n",
    "from pyvis.network import Network\n",
    "#try time slice iteratively\n",
    "# Filter data from specific time period\n",
    "time_slices=[slice('2019-06-01 9:50', '2019-06-01 10:00'),slice('2019-06-01 10:00', '2019-06-01 10:10'),\n",
    "             slice('2019-06-01 10:10', '2019-06-01 10:20'),slice('2019-06-01 10:20', '2019-06-01 10:30'),\n",
    "             slice('2019-06-01 10:30', '2019-06-01 10:40'),slice('2019-06-01 10:40', '2019-06-01 10:50'),\n",
    "             slice('2019-06-01 10:50', '2019-06-01 11:00'),slice('2019-06-01 11:00', '2019-06-01 11:10'),\n",
    "             slice('2019-06-01 11:10', '2019-06-01 11:20')]\n",
    "for i in range(1,10):\n",
    "    time_slice = time_slices[i-1]\n",
    "    m2m_breakout = tmp_m2ms_sorted.loc[time_slice]\n",
    "    # keep only instances with strong signal\n",
    "    m2m_filter_rssi = m2m_breakout[m2m_breakout.rssi >= -70].copy()\n",
    "    print(len(m2m_filter_rssi))\n",
    "    # Count number of time members were in close proximity\n",
    "    # We name the count column \"weight\" so that networkx will use it as weight for the spring layout\n",
    "    m2m_edges = m2m_filter_rssi.groupby(['member1', 'member2'])[['rssi_weighted_mean']\n",
    "                                                               ].count().rename(columns={'rssi_weighted_mean':'weight'})\n",
    "    m2m_edges = m2m_edges[[\"weight\"]].reset_index()\n",
    "    # Keep strongest edges (threshold set manually)\n",
    "    m2m_edges = m2m_edges[m2m_edges.weight > 5]\n",
    "    print(len(m2m_edges))\n",
    "    # Create a graph\n",
    "    graph=nx.from_pandas_edgelist(m2m_edges, \"member1\", \"member2\", \"weight\")\n",
    "#     fig = plt.figure(figsize=(12,90), dpi=150)\n",
    "#     ax = plt.subplot(10,1,i)\n",
    "#     draw_graph(graph, graph_layout=\"spring\",node_size=40)\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "    net.from_nx(graph) \n",
    "#     net.show_buttons()\n",
    "    net.set_options('''\n",
    "    var options = {\n",
    "  \"nodes\": {\n",
    "    \"size\": 12\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"color\": {\n",
    "      \"inherit\": true\n",
    "    },\n",
    "    \"smooth\": false\n",
    "  },\n",
    "  \"interaction\": {\n",
    "    \"hover\": true,\n",
    "    \"keyboard\": {\n",
    "      \"enabled\": true\n",
    "    },\n",
    "    \"navigationButtons\": true,\n",
    "    \"tooltipDelay\": 1000\n",
    "  },\n",
    "  \"manipulation\": {\n",
    "    \"enabled\": true,\n",
    "    \"initiallyActive\": true\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"minVelocity\": 0.75\n",
    "  }\n",
    "}\n",
    "    ''')\n",
    "    net.show(\"Interactivenetworkx{}.html\".format(i))\n",
    "   \n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lunch Time Analysis\n",
    "Use data from lunch time to find the definition of close interaction \n",
    "This part will create a html interactive interface to identify the interactions threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try time slice iteratively\n",
    "# Filter data from specific time period\n",
    "time_slices=[slice('2019-06-01 11:30', '2019-06-01 11:35'),slice('2019-06-01 11:35', '2019-06-01 11:40'),\n",
    "             slice('2019-06-01 11:40', '2019-06-01 11:45'),slice('2019-06-01 11:45', '2019-06-01 11:50'),\n",
    "             slice('2019-06-01 11:50', '2019-06-01 11:55'),slice('2019-06-01 11:55', '2019-06-01 12:00'),\n",
    "            slice('2019-06-01 12:00', '2019-06-01 12:05'),slice('2019-06-01 12:05', '2019-06-01 12:10'),\n",
    "            slice('2019-06-01 12:10', '2019-06-01 12:15'),slice('2019-06-01 12:15', '2019-06-01 12:20'),]\n",
    "for i in range(1,11):\n",
    "    time_slice = time_slices[i-1]\n",
    "    m2m_breakout = tmp_m2ms_sorted.loc[time_slice]\n",
    "    # keep only instances with strong signal\n",
    "    m2m_filter_rssi = m2m_breakout[m2m_breakout.rssi >= -75].copy()\n",
    "    # Count number of time members were in close proximity\n",
    "    # We name the count column \"weight\" so that networkx will use it as weight for the spring layout\n",
    "    m2m_edges = m2m_filter_rssi.groupby(['member1', 'member2'])[['rssi_weighted_mean']\n",
    "                                                               ].count().rename(columns={'rssi_weighted_mean':'weight'})\n",
    "    m2m_edges = m2m_edges[[\"weight\"]].reset_index()\n",
    "    # Keep strongest edges (threshold set manually)\n",
    "    m2m_edges = m2m_edges[m2m_edges.weight > 8]\n",
    "    # Create a graph\n",
    "    graph=nx.from_pandas_edgelist(m2m_edges, \"member1\", \"member2\", \"weight\")\n",
    "    fig = plt.figure(figsize=(12,90), dpi=150)\n",
    "    ax = plt.subplot(10,1,i)\n",
    "    draw_graph(graph, graph_layout=\"spring\",node_size=200)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break-out Session Analysis\n",
    "Use data from lunch time to find the definition of close interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#try time slice iteratively\n",
    "# Filter data from specific time period\n",
    "time_slices=generate_time_slices(9,50,11,20,interval=2)\n",
    "\n",
    "# time slice creation\n",
    "\n",
    "\n",
    "for i in range(1,46):\n",
    "    time_slice = time_slices[i-1]\n",
    "    m2m_breakout = tmp_m2ms_sorted.loc[time_slice]\n",
    "    # keep only instances with strong signal\n",
    "    m2m_filter_rssi = m2m_breakout[m2m_breakout.rssi >= -73].copy()\n",
    "    print(len(m2m_filter_rssi))\n",
    "    # Count number of time members were in close proximity\n",
    "    # We name the count column \"weight\" so that networkx will use it as weight for the spring layout\n",
    "    m2m_edges = m2m_filter_rssi.groupby(['member1', 'member2'])[['rssi_weighted_mean']\n",
    "                                                               ].count().rename(columns={'rssi_weighted_mean':'weight'})\n",
    "    m2m_edges = m2m_edges[[\"weight\"]].reset_index()\n",
    "    # Keep strongest edges (threshold set manually)\n",
    "    m2m_edges = m2m_edges[m2m_edges.weight > 1]\n",
    "    print(len(m2m_edges))\n",
    "    # Create a graph\n",
    "    graph=nx.from_pandas_edgelist(m2m_edges, \"member1\", \"member2\", \"weight\")\n",
    "    fig = plt.figure(figsize=(12,400), dpi=150)\n",
    "    ax = plt.subplot(45,1,i)\n",
    "    draw_graph(graph, graph_layout=\"spring\",node_size=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction Network Graph\n",
    "This tool helps find interaction between members in a certain amount of time with designated parameters, such as signal strength using the distribution of signal strength. This graph draws multiple pictures so that less detailed are lost in generalization. \n",
    "\n",
    "To choose a threshold for signal strength, the program analyzes the distribution of frequencies of signal strength and it will take the frequency of the peak -2. -2 for leave some room for fluctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval_start_h=9\n",
    "time_interval_start_m=50\n",
    "time_interval_end_h=11\n",
    "time_interval_end_m=20\n",
    "interval=2\n",
    "t_count_threshold = 2\n",
    "\n",
    "\n",
    "bo1 = generate_time_points(time_interval_start_h, time_interval_start_m, \n",
    "                           time_interval_end_h, time_interval_end_m, interval)\n",
    "freq_list_1 = []\n",
    "for i in bo1:\n",
    "    freq_list_1.append(tmp_m2ms.reset_index().set_index('datetime').loc[i])\n",
    "\n",
    "hist_list_1 = []\n",
    "for freq in freq_list_1:\n",
    "    tmp_freq = []\n",
    "    for row in freq.iterrows():\n",
    "        tmp = [row[1][3]]*int(row[1][5])\n",
    "        tmp_freq = tmp_freq + tmp\n",
    "    hist_list_1.append(tmp_freq)\n",
    "\n",
    "# print(len(hist_list_1))\n",
    "\n",
    "vals = {}\n",
    "for i in range(len(hist_list_1)): \n",
    "    for j in hist_list_1[i]:\n",
    "        if j not in vals.keys():\n",
    "            vals[j]=1; \n",
    "        else: \n",
    "            vals[j]=vals[j]+1\n",
    "\n",
    "# freq_count = dict(zip(his))\n",
    "# print(vals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "vals_sorted = copy.deepcopy(sorted(vals.items(), key = \n",
    "             lambda vals:(vals[1], vals[0]),reverse = True))\n",
    "sign_threshold = vals_sorted[1][0]\n",
    "print(sign_threshold)\n",
    "# print(vals_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_slices=generate_time_slices(time_interval_start_h,time_interval_start_m,time_interval_end_h,\n",
    "                                 time_interval_end_m,interval)\n",
    "\n",
    "for i in range(1,len(time_slices)+1):\n",
    "    time_slice = time_slices[i-1]\n",
    "    m2m_breakout = tmp_m2ms_sorted.loc[time_slice]\n",
    "    # keep only instances with strong signal\n",
    "    m2m_filter_rssi = m2m_breakout[m2m_breakout.rssi >= sign_threshold].copy()\n",
    "    # print(len(m2m_filter_rssi))\n",
    "    # Count number of time members were in close proximity\n",
    "    # We name the count column \"weight\" so that networkx will use it as weight for the spring layout\n",
    "    m2m_edges = m2m_filter_rssi.groupby(['member1', 'member2'])[['rssi_weighted_mean']\n",
    "                                                               ].count().rename(columns={'rssi_weighted_mean':'weight'})\n",
    "    m2m_edges = m2m_edges[[\"weight\"]].reset_index()\n",
    "    # Keep strongest edges (threshold set manually)\n",
    "    m2m_edges = m2m_edges[m2m_edges.weight > interval/2]\n",
    "    if i == 1: \n",
    "        m2m_edges_count = m2m_edges.copy().assign(t_count = [1 for x in range(1,len(m2m_edges['member1'])+1)])\n",
    "        m2m_edges_count = m2m_edges_count.assign(appeared = [False for x in range(1,len(m2m_edges_count)+1)])\n",
    "    else: \n",
    "        for h in range(1,len(m2m_edges['member1'])):        \n",
    "            for j in range(1,len(m2m_edges_count['member1'])):\n",
    "                if m2m_edges.iloc[h,0]==m2m_edges_count.iloc[j,0] and m2m_edges.iloc[h,1]==m2m_edges_count.iloc[j,1]: \n",
    "                    m2m_edges_count.iloc[j,3]=m2m_edges_count.iloc[j,3]+1 \n",
    "                    m2m_edges_count.iloc[j,4]=True\n",
    "                elif j==len(m2m_edges_count['member1']):\n",
    "                    m2m_edges_count.append({'member1':m2m_edges.iloc[h,0],'member2':m2m_edges.iloc[h,1],\n",
    "                                            'weight':m2m_edges.iloc[h,2],'t_count':m2m_edges.iloc[h,3],\n",
    "                                           'appeared':True})\n",
    "        for j in m2m_edges_count.index.values:            \n",
    "            if m2m_edges_count.loc[j,'appeared']==False:\n",
    "                #print(j)\n",
    "                if m2m_edges_count.loc[j,'t_count']<t_count_threshold: \n",
    "                    m2m_edges_count.drop(j,inplace=True)\n",
    "                #for x in range(1,len(m2m_edges_count)):\n",
    "                    #print m2m_edges_count.iloc[x:x+1]\n",
    "            else: \n",
    "                m2m_edges_count.loc[j,'appeared']=False\n",
    "for x in range(1,len(m2m_edges_count)):\n",
    "    print m2m_edges_count.iloc[x:x+1]\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the graph with filtered interactions \n",
    "graph=nx.from_pandas_edgelist(m2m_edges_count, \"member1\", \"member2\", \"t_count\")\n",
    "fig = plt.figure(figsize=(12,10), dpi=120)\n",
    "draw_graph(graph, graph_layout=\"spring\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use interactive network graph to clearly see who is involved in what interactions \n",
    "from pyvis.network import Network\n",
    "net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "net.from_nx(graph) \n",
    "net.set_options('''\n",
    "    var options = {\n",
    "  \"nodes\": {\n",
    "    \"size\": 12\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"color\": {\n",
    "      \"inherit\": true\n",
    "    },\n",
    "    \"smooth\": false\n",
    "  },\n",
    "  \"interaction\": {\n",
    "    \"hover\": true,\n",
    "    \"keyboard\": {\n",
    "      \"enabled\": true\n",
    "    },\n",
    "    \"navigationButtons\": true,\n",
    "    \"tooltipDelay\": 1000\n",
    "  },\n",
    "  \"manipulation\": {\n",
    "    \"enabled\": true,\n",
    "    \"initiallyActive\": true\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"minVelocity\": 0.75\n",
    "  }\n",
    "}\n",
    "    ''')\n",
    "net.show(\"Interactivenetworkx.html\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporate background information into the dynamic graph\n",
    "\n",
    "# read member background data  \n",
    "attendees_metadata_filename = \"Badge assignments_Attendees_2019.xlsx\"\n",
    "attendees_metadata = pd.read_excel(data_dir+attendees_metadata_filename)\n",
    "background = pd.DataFrame(columns=['name','badge','background','affiliation'])\n",
    "background_affiliation = pd.DataFrame(columns=['name','badge','background','affiliation'])\n",
    "members_metadata = pd.read_csv(data_dir+members_metadata_filename)\n",
    "background['name'] = members_metadata['member']\n",
    "background['badge'] = members_metadata['BADGE IP']\n",
    "for i in background['badge']:\n",
    "    if i in attendees_metadata['BADGE IP'].values:\n",
    "        a = background.loc[background['badge'] == i]\n",
    "        b = attendees_metadata.loc[attendees_metadata['BADGE IP']==i]\n",
    "        a['background'] = b['Cleaned Primary discipline/field of interest'].values\n",
    "        a['affiliation'] = b['Affiliation'].values\n",
    "        background_affiliation = pd.concat([background_affiliation, a])\n",
    "    else:\n",
    "        a = background.loc[background['badge']==i]\n",
    "        background_affiliation = pd.concat([background_affiliation, a])\n",
    "        \n",
    "\n",
    "#create a dictionary for member id and background info\n",
    "bg_dict = {}\n",
    "for i in range(0,len(background_affiliation)):\n",
    "    bg_dict.update({background_affiliation.loc[i,'name']: str(background_affiliation.loc[i,'background'])+\", \"+\n",
    "                                                          str(background_affiliation.loc[i,'affiliation'])+\", \"+\n",
    "                                                          str(i)})\n",
    "    \n",
    "#relabel the nodes with the background infomation\n",
    "graph_bg = nx.relabel_nodes(graph,bg_dict)\n",
    "\n",
    "# create the graph with filtered interactions \n",
    "fig = plt.figure(figsize=(12,10), dpi=150)\n",
    "draw_graph(graph_bg, graph_layout=\"spring\",node_size=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Interaction Finding Tool \n",
    "This tool helps find interaction between members in a certain amount of time with designated parameters, such as signal strength using the distribution of signal strength. These parameters can bu customized. \n",
    "\n",
    "To automatively choose a threshold for signal strength, the program analyzes the distribution of frequencies of signal strength and it will take the frequency of the peak -2. -2 for leave some room for fluctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import GridspecLayout,Layout,IntSlider,Button\n",
    "from numpy import std\n",
    "# import bqplot as bq\n",
    "\n",
    "\n",
    "start_hr = IntSlider(min=7, max=14, value=9, description=\"Start hour: \",\n",
    "                         layout=Layout(width='auto', height='auto')\n",
    "                    )\n",
    "start_min = IntSlider(min=0, max=59, value=50, description=\"Start min: \",\n",
    "                         layout=Layout(width='auto', height='auto')\n",
    "                     )\n",
    "end_hr = IntSlider(min=7, max=14, value=11, description=\"End hour: \",\n",
    "                         layout=Layout(width='auto', height='auto')\n",
    "                  )\n",
    "end_min = IntSlider(min=0, max=59, value=30,description=\"End min: \",\n",
    "                         layout=Layout(width='auto', height='auto')\n",
    "                   )\n",
    "interval_threshold = IntSlider(min=2, max=10, value=2,description=\"Time interval: \",\n",
    "                         layout=Layout(width='auto', height='auto')\n",
    "                    )\n",
    "time_count_threshold = IntSlider(min=0, max=90, value=2,description=\"Time count threshold: \",\n",
    "                         layout=Layout(width='auto', height='auto')\n",
    "                    )\n",
    "app = GridspecLayout(3, 3, height='100px')\n",
    "\n",
    "app[0,0]=start_hr\n",
    "app[0,1]=start_min\n",
    "app[0,2]=end_hr\n",
    "app[1,0]=end_min\n",
    "app[1,1]=interval_threshold\n",
    "app[1,2]=time_count_threshold\n",
    "\n",
    "\n",
    "\n",
    "def start_hr_change(change):\n",
    "    time_interval_start_h=change['new']\n",
    "#     print(time_interval_start_h)\n",
    "    \n",
    "def start_min_change(change):\n",
    "    time_interval_start_h=change['new']\n",
    "#     print(time_interval_start_m)\n",
    "    \n",
    "def end_hr_change(change):\n",
    "    time_interval_start_h=change['new']\n",
    "#     print(time_interval_end_h)\n",
    "    \n",
    "def end_min_change(change):\n",
    "    time_interval_start_h=change['new']\n",
    "#     print(time_interval_end_m)\n",
    "\n",
    "def interval_threshold_change(change):\n",
    "    interval=change['new']\n",
    "    print(interval)\n",
    "    \n",
    "def time_count_threshold_change(change):\n",
    "    t_count_threshold=change['new']\n",
    "#     print(t_count_threshold)\n",
    "\n",
    "start_hr.observe(start_hr_change, names='value')\n",
    "start_min.observe(start_min_change, names='value')\n",
    "end_hr.observe(end_hr_change, names='value')\n",
    "end_min.observe(end_min_change, names='value')\n",
    "interval_threshold.observe(interval_threshold_change, names='value')\n",
    "time_count_threshold.observe(time_count_threshold_change, names='value')\n",
    "\n",
    "\n",
    "draw_graph_button=Button(description='Draw graph!', button_style='info', layout=Layout(height='auto', width='auto'))\n",
    "app[2,:]=draw_graph_button\n",
    "\n",
    "display(app)\n",
    "\n",
    "\n",
    "\n",
    "def draw_graph_button_click_handler(btn_object):\n",
    "    print('You pressed the {} button!'.format(btn_object.description))\n",
    "    time_interval_start_h=start_hr.value\n",
    "    time_interval_start_m=start_min.value\n",
    "    time_interval_end_h=end_hr.value\n",
    "    time_interval_end_m=end_min.value\n",
    "    interval=interval_threshold.value\n",
    "    t_count_threshold=time_count_threshold.value\n",
    "    bo1 = generate_time_points(time_interval_start_h, time_interval_start_m, \n",
    "                           time_interval_end_h, time_interval_end_m, interval)\n",
    "    freq_list_1 = []\n",
    "    for i in bo1:\n",
    "        freq_list_1.append(tmp_m2ms.reset_index().set_index('datetime').loc[i])\n",
    "\n",
    "    hist_list_1 = []\n",
    "    for freq in freq_list_1:\n",
    "        tmp_freq = []\n",
    "        for row in freq.iterrows():\n",
    "            tmp = [row[1][3]]*int(row[1][5])\n",
    "            tmp_freq = tmp_freq + tmp\n",
    "        hist_list_1.append(tmp_freq)\n",
    "\n",
    "    # print(len(hist_list_1))\n",
    "\n",
    "    vals = {}\n",
    "    for i in range(len(hist_list_1)): \n",
    "        for j in hist_list_1[i]:\n",
    "            if j not in vals.keys():\n",
    "                vals[j]=1; \n",
    "            else: \n",
    "                vals[j]=vals[j]+1\n",
    "      \n",
    "    \n",
    "    import copy\n",
    "    vals_sorted = copy.deepcopy(sorted(vals.items(), key = \n",
    "                 lambda vals:(vals[1], vals[0]),reverse = True))\n",
    "    sign_threshold = vals_sorted[2][0]\n",
    "    print('The threshold we find from distribution is '+ str(sign_threshold))\n",
    "    # print(vals_sorted)\n",
    "    \n",
    "\n",
    "    time_slices=generate_time_slices(time_interval_start_h,time_interval_start_m,time_interval_end_h,\n",
    "                                     time_interval_end_m,interval)\n",
    "    \n",
    "    for i in range(1,len(time_slices)+1):\n",
    "#         print(i)\n",
    "        time_slice = time_slices[i-1]\n",
    "        m2m_breakout = tmp_m2ms_sorted.loc[time_slice]\n",
    "        # keep only instances with strong signal\n",
    "        m2m_filter_rssi = m2m_breakout[m2m_breakout.rssi >= sign_threshold].copy()\n",
    "        # print(len(m2m_filter_rssi))\n",
    "        # Count number of time members were in close proximity\n",
    "        # We name the count column \"weight\" so that networkx will use it as weight for the spring layout\n",
    "        m2m_edges = m2m_filter_rssi.groupby(['member1', 'member2'])[['rssi_weighted_mean']\n",
    "                                                                   ].count().rename(columns={'rssi_weighted_mean':'weight'})\n",
    "        m2m_edges = m2m_edges[[\"weight\"]].reset_index()\n",
    "        # Keep strongest edges (threshold set manually)\n",
    "        m2m_edges = m2m_edges[m2m_edges.weight > interval/2]\n",
    "        if i == 1: \n",
    "            m2m_edges_count = m2m_edges.copy().assign(t_count = [1 for x in range(1,len(m2m_edges['member1'])+1)])\n",
    "            m2m_edges_count = m2m_edges_count.assign(appeared = [False for x in range(1,len(m2m_edges_count)+1)])\n",
    "        else: \n",
    "            for h in range(1,len(m2m_edges['member1'])):        \n",
    "                for j in range(1,len(m2m_edges_count['member1'])):\n",
    "                    if m2m_edges.iloc[h,0]==m2m_edges_count.iloc[j,0] and m2m_edges.iloc[h,1]==m2m_edges_count.iloc[j,1]: \n",
    "                        m2m_edges_count.iloc[j,3]=m2m_edges_count.iloc[j,3]+1 \n",
    "                        m2m_edges_count.iloc[j,4]=True\n",
    "                    elif j==len(m2m_edges_count['member1']):\n",
    "                        m2m_edges_count.append({'member1':m2m_edges.iloc[h,0],'member2':m2m_edges.iloc[h,1],\n",
    "                                                'weight':m2m_edges.iloc[h,2],'t_count':m2m_edges.iloc[h,3],\n",
    "                                               'appeared':True})\n",
    "            for j in m2m_edges_count.index.values:            \n",
    "                if m2m_edges_count.loc[j,'appeared']==False:\n",
    "                    #print(j)\n",
    "                    if m2m_edges_count.loc[j,'t_count']<t_count_threshold: \n",
    "                        m2m_edges_count.drop(j,inplace=True)\n",
    "                    #for x in range(1,len(m2m_edges_count)):\n",
    "                        #print m2m_edges_count.iloc[x:x+1]\n",
    "                else: \n",
    "                    m2m_edges_count.loc[j,'appeared']=False\n",
    "#         for x in range(1,len(m2m_edges_count)):\n",
    "#             print m2m_edges_count.iloc[x:x+1]\n",
    "\n",
    "    \n",
    "    graph=nx.from_pandas_edgelist(m2m_edges_count, \"member1\", \"member2\", \"t_count\")\n",
    "    \n",
    "\n",
    "    # incorporate background information into the dynamic graph\n",
    "\n",
    "    # read member background data  \n",
    "    attendees_metadata_filename = \"Badge assignments_Attendees_2019.xlsx\"\n",
    "    attendees_metadata = pd.read_excel(data_dir+attendees_metadata_filename)\n",
    "    background = pd.DataFrame(columns=['name','badge','background','affiliation'])\n",
    "    background_affiliation = pd.DataFrame(columns=['name','badge','background','affiliation'])\n",
    "    members_metadata = pd.read_csv(data_dir+members_metadata_filename)\n",
    "    background['name'] = members_metadata['member']\n",
    "    background['badge'] = members_metadata['BADGE IP']\n",
    "    for i in background['badge']:\n",
    "        if i in attendees_metadata['BADGE IP'].values:\n",
    "            a = background.loc[background['badge'] == i]\n",
    "            b = attendees_metadata.loc[attendees_metadata['BADGE IP']==i]\n",
    "            a['background'] = b['Cleaned Primary discipline/field of interest'].values\n",
    "            a['affiliation'] = b['Affiliation'].values\n",
    "            background_affiliation = pd.concat([background_affiliation, a])\n",
    "        else:\n",
    "            a = background.loc[background['badge']==i]\n",
    "            background_affiliation = pd.concat([background_affiliation, a])\n",
    "\n",
    "\n",
    "    #create a dictionary for member id and background info\n",
    "    bg_dict = {}\n",
    "    for i in range(0,len(background_affiliation)):\n",
    "        bg_dict.update({background_affiliation.loc[i,'name']: str(background_affiliation.loc[i,'background'])+\", \"+\n",
    "                                                              str(background_affiliation.loc[i,'affiliation'])+\", \"+\n",
    "                                                              str(i)})\n",
    "\n",
    "    #relabel the nodes with the background infomation\n",
    "    graph_bg = nx.relabel_nodes(graph,bg_dict)\n",
    "\n",
    "    # create the graph with filtered interactions \n",
    "    fig = plt.figure(figsize=(12,10), dpi=150)\n",
    "    draw_graph(graph_bg, graph_layout=\"spring\",node_size=60)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "draw_graph_button.on_click(draw_graph_button_click_handler)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
